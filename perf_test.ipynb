{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for perf-testing PyTorch vs TensorFlow with and without GPU on a simple training set so I can figure out the best environment for training models. Here's the setup I used\n",
    "* Windows 11, i7-10 16GB RAM, RTX 2060 GPU w 6 GB RAM, VS Code\n",
    "* Fashion mnista data set with simple model with 3 dense layers\n",
    "* Tensorflow w CUDA via WSL set up per https://www.tensorflow.org/install/pip\n",
    "* Tensorflow w CUDA via direct ML set up per https://learn.microsoft.com/en-us/windows/ai/directml/gpu-tensorflow-plugin\n",
    "\n",
    "Here are the results so far:\n",
    "1) Tensorflow w CPU: 17 seconds\n",
    "2) Tensorflow w CUDA via WSL: 32 seconds. Plus WSL is horrible on so many levels (see below)\n",
    "3) Tensorflow w CUDA via direct ML: 40 seconds. Even worse, but not horrible like WSL (see below) and while the perf on this small model was worse than cpu, it significantly sped up the training of a deeper unet model I tested it on; from 5.5 hours to 25 minutes!\n",
    "4) PyTorch with or without without CUDA: 128 seconds. By far the worst; I must be doing something wrong. Hopefully the internet can help me.\n",
    "\n",
    "My WSL experience:\n",
    "* Setting it up was a complete PITA\n",
    "* After following all the instructions, you still get spurrious warnings about tensorRT and NUMA\n",
    "* WSL eats up a ton of disk space, and worse it eats up a ton or RAM when running, and 1GB or RAM even when it is not running(!) due to virualization of the operation systems\n",
    "* And for all this, it has negative benefit, so I've uninstalled for now and will wait for the tech to mature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Description: This file is used to test the performance of WSL + GPU vs WSL + CPU, vs Windows + CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "HAS_GPU = len (tf.config.list_physical_devices(\"GPU\")) > 0\n",
    "if HAS_GPU:\n",
    "    print(\"Available GPU devices:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.8054\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4049 - accuracy: 0.8521\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3707 - accuracy: 0.8642\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3494 - accuracy: 0.8698\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3354 - accuracy: 0.8767\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3218 - accuracy: 0.8806\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3112 - accuracy: 0.8841\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3038 - accuracy: 0.8872\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2956 - accuracy: 0.8888\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2875 - accuracy: 0.8919\n",
      "CPU Training time: 15.70 seconds\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5349 - accuracy: 0.8068\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4043 - accuracy: 0.8520\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3691 - accuracy: 0.8629\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3471 - accuracy: 0.8717\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3337 - accuracy: 0.8765\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3209 - accuracy: 0.8804\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3107 - accuracy: 0.8842\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3019 - accuracy: 0.8861\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2971 - accuracy: 0.8893\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2894 - accuracy: 0.8917\n",
      "GPU Training time: 39.75 seconds\n",
      "GPU:0 physical memory: {'current': 295487232, 'peak': 296705792}\n",
      "Test accuracy: 0.8824, loss: 0.3320\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 12    # 12th man - go Seahawks!\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train/255.0\n",
    "x_test  = x_test/255.0\n",
    "\n",
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = get_model()\n",
    "    current_time = tf.timestamp()\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    elapsed_time = tf.timestamp() - current_time\n",
    "    print (f\"CPU Training time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "if HAS_GPU:\n",
    "    model = get_model()\n",
    "    current_time = tf.timestamp()\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    elapsed_time = tf.timestamp() - current_time\n",
    "    print (f\"GPU Training time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"GPU:0 physical memory: {tf.config.experimental.get_memory_info('GPU:0')}\")\n",
    "\n",
    "# Print accuracy and loss on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f}, loss: {test_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print (f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...Avg loss: 0.0084\n",
      "Epoch 2...Avg loss: 0.0065\n",
      "Epoch 3...Avg loss: 0.0060\n",
      "Epoch 4...Avg loss: 0.0056\n",
      "Epoch 5...Avg loss: 0.0053\n",
      "Epoch 6...Avg loss: 0.0051\n",
      "Epoch 7...Avg loss: 0.0050\n",
      "Epoch 8...Avg loss: 0.0048\n",
      "Epoch 9...Avg loss: 0.0047\n",
      "Epoch 10...Avg loss: 0.0046\n",
      "cuda Training time: 125.60 seconds\n",
      "Accuracy: 87.1%, Avg loss: 0.005769 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "DIR = \"data/fashionmnist\"\n",
    "RANDOM_SEED = 12    # 12th man - go Seahawks!\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    "    ).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Get the fashion mnist training data and normalize it\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train = datasets.FashionMNIST(DIR, download=True, train=True, transform=transform)\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    avg_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        avg_loss += loss.item()\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return avg_loss / size\n",
    "\n",
    "current_time = time.time()\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}...\", end=\"\")\n",
    "    avg_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    print(f\"Avg loss: {avg_loss:.4f}\")\n",
    "elapsed_time = time.time() - current_time\n",
    "print (f\"{device} Training time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "test = datasets.FashionMNIST(DIR, download=True, train=False, transform=transform)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loop(test_loader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
